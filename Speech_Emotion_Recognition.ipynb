{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech-Emotion-Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxEKSsOnivMG7dhoFTebnN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitrv8922/Speech-Emotion-Recognition-Detection/blob/main/Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "5R3fwJ_p5I7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7C21R0TR5K9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f810f946-5a5a-4b59-cae7-a090f3c3781c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project Introduction"
      ],
      "metadata": {
        "id": "dvOvgS7f9lbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "iC-Np-f49rJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the required Libraries\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential                                                            \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization,GlobalMaxPool2D,Activation,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ppZc3k9sol",
        "outputId": "16ef1e75-2863-468f-98da-c8fe8f8dc923"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "        print(os.listdir(\"../input\"))"
      ],
      "metadata": {
        "id": "PSOg-g-W3Fs_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df='/content/drive/My Drive/'\n",
        "face_df=pd.read_csv(df +'/Dataset/icml_face_data.csv',encoding='latin-1')\n",
        "face_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B7ZKXKG8H-3n",
        "outputId": "0584f192-58c6-40da-f7b8-e898e5d734df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion     Usage                                             pixels\n",
              "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cecd9023-a19e-4062-9fc1-29a0c2936e20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cecd9023-a19e-4062-9fc1-29a0c2936e20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cecd9023-a19e-4062-9fc1-29a0c2936e20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cecd9023-a19e-4062-9fc1-29a0c2936e20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    \"\"\" Prepare data for modeling \n",
        "        input: data frame with labels und pixel data\n",
        "        output: image and label array \"\"\"\n",
        "    \n",
        "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\n",
        "    \n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image_array[i] = image\n",
        "\n",
        "    return image_array, image_label\n",
        "  \n",
        "def plot_examples(label=0):\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n",
        "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
        "    axs = axs.ravel()\n",
        "    for i in range(5):\n",
        "        idx = data[data['emotion']==label].index[i]\n",
        "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
        "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_yticklabels([])\n",
        "def plot_all_emotions():\n",
        "    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n",
        "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
        "    axs = axs.ravel()\n",
        "    for i in range(7):\n",
        "        idx = data[data['emotion']==i].index[i]\n",
        "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
        "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_yticklabels([])\n",
        "\n",
        "def plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n",
        "    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
        "    \n",
        "    bar_label = emotions.values()\n",
        "    \n",
        "    axs[0].imshow(test_image_array[image_number], 'gray')\n",
        "    axs[0].set_title(emotions[test_image_label[image_number]])\n",
        "    \n",
        "    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_distributions(array1, array2, title1='', title2=''):\n",
        "    df_array1 = pd.DataFrame()\n",
        "    df_array2 = pd.DataFrame()\n",
        "    df_array1['emotion'] = array1.argmax(axis=1)\n",
        "    df_array2['emotion'] = array2.argmax(axis=1)\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
        "    x = emotions.values()\n",
        "    \n",
        "    y = df_array1['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[0].bar(x, y.sort_index(), color='orange')\n",
        "    axs[0].set_title(title1)\n",
        "    axs[0].grid()\n",
        "\n",
        "    y = df_array2['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[1].bar(x, y.sort_index())\n",
        "    axs[1].set_title(title2)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()                "
      ],
      "metadata": {
        "id": "nPuEl1Ii3V-c"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def callbackFunction(modelName):\n",
        "  checkpoint = ModelCheckpoint(f\"Checkpoints/{modelName}.h5\", monitor = \"val_accuracy\", save_best_only = True, mode = \"auto\", verbose = 1)\n",
        "  early_stopping = EarlyStopping(monitor = \"val_accuracy\", patience = 10, verbose = 1)\n",
        "  callbacks = [early_stopping, checkpoint]\n",
        "  return callbacks"
      ],
      "metadata": {
        "id": "dSP5wvIG36fn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_df[' Usage'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVXjNv8Y36qK",
        "outputId": "bfa6d38a-b0a0-430b-a9e0-6e0bb48c2eb3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name:  Usage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
      ],
      "metadata": {
        "id": "q_WWuw6H4Lo7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining train and validation path\n",
        "train_path = pd.read_csv('/content/drive/My Drive/Dataset/train.csv')\n",
        "val_path = pd.read_csv('/content/drive/My Drive/Dataset/test.csv')"
      ],
      "metadata": {
        "id": "UHXOWhFlIb9b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data categories\n",
        "categories = (train_path)\n",
        "print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDWQWjk0rvrm",
        "outputId": "ef3fc4d6-5b20-49fd-c3ed-355167b2aa9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       emotion                                             pixels\n",
            "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1            0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2            2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
            "...        ...                                                ...\n",
            "28704        2  84 85 85 85 85 85 85 85 86 86 86 87 86 86 91 9...\n",
            "28705        0  114 112 113 113 111 111 112 113 115 113 114 11...\n",
            "28706        4  74 81 87 89 95 100 98 93 105 120 127 133 146 1...\n",
            "28707        0  222 227 203 90 86 90 84 77 94 87 99 119 134 14...\n",
            "28708        4  195 199 205 206 205 203 206 209 208 210 212 21...\n",
            "\n",
            "[28709 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for using for show some images from each categories\n",
        "def imageshow(category):\n",
        "  plt.figure(figsize= (8,8))\n",
        "  for i in range(1, 10, 1):\n",
        "      plt.subplot(3,3,i)\n",
        "      img = load_img(train_path+'/'+category+\"/\"+\n",
        "                    os.listdir(train_path + \"/\" + category)[i], target_size=(48,48))\n",
        "      plt.imshow(img)\n",
        "  plt.suptitle(category,fontsize=30)   \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uK-_QH1J5Etj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Showing some images from category neutral\n",
        "imageshow('neutral')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "E0HsWhcP5I8a",
        "outputId": "132937ec-71df-43ec-d05c-83977d842bd6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-517a543e6a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Showing some images from category neutral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimageshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-b1b9007c762c>\u001b[0m in \u001b[0;36mimageshow\u001b[0;34m(category)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       img = load_img(train_path+'/'+category+\"/\"+\n\u001b[0m\u001b[1;32m      7\u001b[0m                     os.listdir(train_path + \"/\" + category)[i], target_size=(48,48))\n\u001b[1;32m      8\u001b[0m       \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__add__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__radd__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6866\u001b[0;31m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6867\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   6891\u001b[0m             \u001b[0;31m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6892\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6893\u001b[0;31m                 \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6894\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U1')) -> None"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}