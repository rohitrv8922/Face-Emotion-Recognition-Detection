{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech-Emotion-Recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOm02/0+ZSjoszZTBNy1xe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitrv8922/Speech-Emotion-Recognition-Detection/blob/main/Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "5R3fwJ_p5I7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7C21R0TR5K9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ac2982-0cc6-4447-8474-ac1daee4c1d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project Introduction"
      ],
      "metadata": {
        "id": "dvOvgS7f9lbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "iC-Np-f49rJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the required Libraries\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential                                                            \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization,GlobalMaxPool2D,Activation,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ppZc3k9sol",
        "outputId": "ccce981d-b13d-4e73-ae2d-4de4bfc41aa4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import zipfile\n",
        "import os\n",
        "#Opens the zip file in read mode\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Dataset/icml_face_data.csv.zip', 'r')\n",
        "#Extracts the files in folder\n",
        "zip_ref.extractall('/content/drive/MyDrive/Dataset') \n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "B7ZKXKG8H-3n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining train and validation path\n",
        "train_path = '/content/drive/MyDrive/Dataset/train.csv'\n",
        "val_path = '/o-ntent/drive/MyDrive/Dataset/validation'"
      ],
      "metadata": {
        "id": "UHXOWhFlIb9b"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training images\n",
        "total_train_images = 0\n",
        "for dir_ in os.listdir(train_path):\n",
        "    count = 0\n",
        "    for f in os.listdir(train_path+'/' + dir_+\"/\"):\n",
        "        count += 1\n",
        "        total_train_images += 1\n",
        "    print(f\"{dir_} has {count} number of images\")\n",
        "    \n",
        "print(f\"\\ntotal train images are {total_train_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "_Ts-jfJZJBVt",
        "outputId": "bedeb133-a568-41b6-f74d-8777c9d2113b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-6aa88190d2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_train_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdir_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdir_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "0sDhfkkpMciU"
      }
    }
  ]
}